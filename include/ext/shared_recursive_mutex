/**
 * @file shared_recursive_mutex
 * @author Jung-kang Lee (ntoskrnl7@gmail.com)
 * @brief This module implements shared recursive mutex class.
 *
 * @copyright Copyright (c) 2020 C++ Extended template library Authors
 *
 */
#pragma once

#include "stl_compat"

#ifdef CXX_SHARED_MUTEX
#ifndef _EXT_SHARED_RECURSIVE_MUTEX_
#define _EXT_SHARED_RECURSIVE_MUTEX_

#include <atomic>
#include <thread>
#include <unordered_map>
#include <shared_mutex>

namespace ext {
/**
 * @brief The shared_recursive_mutex class
 */
class shared_recursive_mutex : public CXX_SHARED_MUTEX {
public:
  void lock(void) {
    std::thread::id this_id = std::this_thread::get_id();
    if (owner_ == this_id) {
      ++lock_count_;
    } else {
      // When an exclusive lock is in progress by the current thread,
      // if the shared lock is already locked, unlock the share and perform an
      // exclusive lock.
      if (owner_ == std::thread::id()) {
        bool needToUnlockShared = false;
        {
          std::shared_lock<CXX_SHARED_MUTEX> lock(
              shared_lock_count_map_mutex_);
          auto iter = shared_lock_count_map_.find(this_id);
          if (iter != shared_lock_count_map_.cend()) {
            iter->second = 1; // Set only one shared lock to remain unlocked
                              // when the unlock_shared method is called.
            needToUnlockShared = true;
          }
        }
        if (needToUnlockShared)
          unlock_shared();
      }

      CXX_SHARED_MUTEX::lock();
      owner_ = this_id;
      lock_count_ = 1;
    }
  }

  void unlock(void) {
    std::thread::id this_id = std::this_thread::get_id();
    if (owner_ != this_id)
      throw std::system_error(std::error_code(ENOLCK, std::system_category()));

    if (--lock_count_ == 0) {
      owner_ = std::thread::id();
      CXX_SHARED_MUTEX::unlock();
    }
  }

  void lock_shared(void) {
    std::thread::id this_id = std::this_thread::get_id();
    bool needToLock = false;
    {
      std::unique_lock<CXX_SHARED_MUTEX> lock(
          shared_lock_count_map_mutex_);
      auto iter = shared_lock_count_map_.find(this_id);
      if (iter == shared_lock_count_map_.cend()) {
        shared_lock_count_map_.insert({this_id, 1});
        needToLock = true;
      } else {
        ++iter->second;
      }
    }
    if (needToLock) {
      // If the current thread already has an exclusive lock, do not use a
      // shared lock. (Even if there is an exclusive lock, the shared lock count
      // will increase, so I handled it this way.)
      if (owner_ != this_id)
        CXX_SHARED_MUTEX::lock_shared();
    }
  }

  void unlock_shared(void) {
    std::thread::id this_id = std::this_thread::get_id();

    // If the shared lock is already unlocked because it has been switched to a
    // shared lock, it is handled not to unlock it.
    bool needToUnlock = false;
    {
      std::unique_lock<CXX_SHARED_MUTEX> lock(
          shared_lock_count_map_mutex_);
      auto iter = shared_lock_count_map_.find(this_id);
      if (iter != shared_lock_count_map_.cend()) {
        if (--iter->second == 0) {
          shared_lock_count_map_.erase(iter);
          needToUnlock = true;
        }
      }
    }

    if (needToUnlock) {
      // If the current thread is exclusively locked, do not release the shared
      // lock as it has not been held.
      if (owner_ != this_id)
        CXX_SHARED_MUTEX::unlock_shared();
    }
  }

private:
  std::atomic<std::thread::id> owner_;
  std::atomic<unsigned long> lock_count_;

  CXX_SHARED_MUTEX shared_lock_count_map_mutex_;
  std::unordered_map<std::thread::id, unsigned long> shared_lock_count_map_;
};
} // namespace ext

#endif // _EXT_SHARED_RECURSIVE_MUTEX_
#endif // CXX_SHARED_MUTEX